{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from typing import Dict, List\n",
    "\n",
    "# class SimpleTSVValidator:\n",
    "#     def __init__(self):\n",
    "#         self.test_cases = []\n",
    "        \n",
    "#     def load_tsv_file(self, file_path: str):\n",
    "#         \"\"\"TSV íŒŒì¼ì„ ê°„ë‹¨í•˜ê²Œ ë¡œë“œ\"\"\"\n",
    "#         try:\n",
    "#             # TSVë¡œ ì½ê¸° (íƒ­ êµ¬ë¶„ì ì‚¬ìš©)\n",
    "#             df = pd.read_csv(file_path, sep='\\t', encoding='utf-8', header=1)\n",
    "            \n",
    "#             # ì»¬ëŸ¼ëª… ì •ë¦¬ (ëì— ë¶™ì€ ì‰¼í‘œ ì œê±°)\n",
    "#             df.columns = df.columns.str.rstrip(',').str.strip()\n",
    "            \n",
    "#             # ë°ì´í„° ì •ë¦¬ (ê° ì…€ì˜ ëì— ë¶™ì€ ì‰¼í‘œ ì œê±°)\n",
    "#             for col in df.columns:\n",
    "#                 if df[col].dtype == 'object':\n",
    "#                     df[col] = df[col].astype(str).str.rstrip(',').str.strip()\n",
    "            \n",
    "#             print(f\"âœ… TSV íŒŒì¼ ë¡œë“œ ì„±ê³µ: {len(df)}ê°œ í–‰\")\n",
    "#             print(f\"ğŸ“‹ ì»¬ëŸ¼: {list(df.columns)}\")\n",
    "            \n",
    "#             # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±\n",
    "#             for idx, row in df.iterrows():\n",
    "#                 # NaN ê°’ì„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜\n",
    "#                 def safe_str(value):\n",
    "#                     if pd.isna(value) or str(value).lower() == 'nan':\n",
    "#                         return ''\n",
    "#                     return str(value).strip()\n",
    "                \n",
    "#                 # keys-ì •ë‹µì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "#                 expected_keys_str = safe_str(row['keys-ì •ë‹µ'])\n",
    "#                 expected_keys = [k.strip() for k in expected_keys_str.split(',') if k.strip() and k.strip().lower() != 'nan']\n",
    "                \n",
    "#                 # keys_combinedë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "#                 actual_keys_str = safe_str(row['keys_combined'])\n",
    "#                 actual_keys = [k.strip() for k in actual_keys_str.split(',') if k.strip() and k.strip().lower() != 'nan']\n",
    "                \n",
    "#                 # actual_keysì—ì„œ click_type ì œì™¸ (keys-ì •ë‹µì—ëŠ” click_typeì´ ì—†ì„ ì˜ˆì •)\n",
    "#                 actual_keys_filtered = [k for k in actual_keys if k != 'click_type']\n",
    "                \n",
    "#                 # values_combinedë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "#                 values_str = safe_str(row['values_combined'])\n",
    "#                 values = [v.strip() for v in values_str.split(',') if v.strip() and v.strip().lower() != 'nan']\n",
    "                \n",
    "#                 test_case = {\n",
    "#                     'unique_id': idx + 1,\n",
    "#                     'ê¸°ëŠ¥': safe_str(row['ê¸°ëŠ¥']),\n",
    "#                     'ê²½ë¡œ': safe_str(row['ê²½ë¡œ']),\n",
    "#                     'í™œë™': safe_str(row['í™œë™']),\n",
    "#                     'page_id': safe_str(row['page_id']),\n",
    "#                     'act_type': safe_str(row['act_type']),\n",
    "#                     'click_type': safe_str(row['click_type']),\n",
    "#                     'expected_keys': expected_keys,  # keys-ì •ë‹µ (click_type ì—†ìŒ)\n",
    "#                     'actual_keys': actual_keys_filtered,  # keys_combinedì—ì„œ click_type ì œì™¸\n",
    "#                     'actual_keys_original': actual_keys,  # ì›ë³¸ actual_keys (ì°¸ê³ ìš©)\n",
    "#                     'values': values\n",
    "#                 }\n",
    "#                 self.test_cases.append(test_case)\n",
    "                \n",
    "#             print(f\"âœ… í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±: {len(self.test_cases)}ê°œ\")\n",
    "#             print(f\"â„¹ï¸  ê²€ì¦ ì‹œ actual_keysì—ì„œ click_type ì œì™¸ë¨\")\n",
    "            \n",
    "#         except Exception as e:\n",
    "#             print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "#             raise\n",
    "    \n",
    "#     def validate_and_export(self, output_file: str):\n",
    "#         \"\"\"ê²€ì¦ ìˆ˜í–‰ ë° ê²°ê³¼ ì¶œë ¥ (click_type ì œì™¸)\"\"\"\n",
    "#         results = []\n",
    "        \n",
    "#         # NaN ê°’ ì•ˆì „ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "#         def safe_str_result(value):\n",
    "#             if pd.isna(value) or str(value).lower() == 'nan':\n",
    "#                 return ''\n",
    "#             return str(value).strip()\n",
    "        \n",
    "#         for test_case in self.test_cases:\n",
    "#             unique_id = test_case['unique_id']\n",
    "#             actual_keys = test_case['actual_keys']  # click_type ì œì™¸ëœ í‚¤ë“¤\n",
    "#             expected_keys = test_case['expected_keys']\n",
    "#             values = test_case['values']\n",
    "#             actual_keys_original = test_case['actual_keys_original']  # ì›ë³¸ í‚¤ë“¤\n",
    "            \n",
    "#             # keys_combinedê°€ ë¹„ì–´ìˆê±°ë‚˜ actual_keysê°€ ë¹„ì–´ìˆìœ¼ë©´ ë¡œê·¸ ëˆ„ë½\n",
    "#             if len(actual_keys) == 0 and len(expected_keys) > 0:\n",
    "#                 results.append({\n",
    "#                     'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "#                     'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "#                     'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "#                     'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "#                     'page_id': safe_str_result(test_case['page_id']),\n",
    "#                     'act_type': safe_str_result(test_case['act_type']),\n",
    "#                     'click_type': safe_str_result(test_case['click_type']),\n",
    "#                     'key': 'LOG_MISSING',\n",
    "#                     'value': 'ë¡œê·¸ ëˆ„ë½',\n",
    "#                     'pass': 'FAIL'\n",
    "#                 })\n",
    "#                 continue\n",
    "            \n",
    "#             # expected_keysë„ ë¹„ì–´ìˆê³  actual_keysë„ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸°\n",
    "#             if len(actual_keys) == 0 and len(expected_keys) == 0:\n",
    "#                 continue\n",
    "            \n",
    "#             # key-value ë§¤í•‘ (ì›ë³¸ í‚¤ë“¤ ê¸°ì¤€ìœ¼ë¡œ ë§¤í•‘)\n",
    "#             key_value_map = {}\n",
    "#             for i, key in enumerate(actual_keys_original):\n",
    "#                 if i < len(values):\n",
    "#                     key_value_map[key] = safe_str_result(values[i])\n",
    "#                 else:\n",
    "#                     key_value_map[key] = ''\n",
    "            \n",
    "#             actual_keys_set = set(actual_keys)  # click_type ì œì™¸ëœ í‚¤ë“¤\n",
    "#             expected_keys_set = set(expected_keys)\n",
    "            \n",
    "#             # ì˜ˆìƒ í‚¤ ê²€ì¦ (click_type ì œì™¸ëœ actual_keysì™€ ë¹„êµ)\n",
    "#             for key in expected_keys:\n",
    "#                 value = key_value_map.get(key, 'MISSING')\n",
    "#                 pass_status = 'PASS' if key in actual_keys_set else 'FAIL'\n",
    "                \n",
    "#                 results.append({\n",
    "#                     'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "#                     'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "#                     'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "#                     'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "#                     'page_id': safe_str_result(test_case['page_id']),\n",
    "#                     'act_type': safe_str_result(test_case['act_type']),\n",
    "#                     'click_type': safe_str_result(test_case['click_type']),\n",
    "#                     'key': key,\n",
    "#                     'value': safe_str_result(value),\n",
    "#                     'pass': pass_status\n",
    "#                 })\n",
    "            \n",
    "#             # ì˜ˆìƒì¹˜ ëª»í•œ í‚¤ í™•ì¸ (click_type ì œì™¸ëœ actual_keys ê¸°ì¤€)\n",
    "#             unexpected_keys = actual_keys_set - expected_keys_set\n",
    "#             for key in unexpected_keys:\n",
    "#                 value = key_value_map.get(key, '')\n",
    "#                 results.append({\n",
    "#                     'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "#                     'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "#                     'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "#                     'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "#                     'page_id': safe_str_result(test_case['page_id']),\n",
    "#                     'act_type': safe_str_result(test_case['act_type']),\n",
    "#                     'click_type': safe_str_result(test_case['click_type']),\n",
    "#                     'key': key,\n",
    "#                     'value': safe_str_result(value),\n",
    "#                     'pass': 'UNEXPECTED'\n",
    "#                 })\n",
    "        \n",
    "#         # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "#         df_results = pd.DataFrame(results)\n",
    "        \n",
    "#         # Excelë¡œ ì €ì¥\n",
    "#         df_results.to_excel(output_file, index=False, engine='openpyxl')\n",
    "        \n",
    "#         # ìš”ì•½ ì¶œë ¥\n",
    "#         self._print_summary(results)\n",
    "#         print(f\"âœ… ê²°ê³¼ ì €ì¥: {output_file}\")\n",
    "        \n",
    "#         return results\n",
    "\n",
    "#     def _print_summary(self, results: List[Dict]):\n",
    "#         \"\"\"ê²°ê³¼ ìš”ì•½\"\"\"\n",
    "#         df = pd.DataFrame(results)\n",
    "        \n",
    "#         total = len(df)\n",
    "#         passed = len(df[df['pass'] == 'PASS'])\n",
    "#         failed = len(df[df['pass'] == 'FAIL'])\n",
    "#         unexpected = len(df[df['pass'] == 'UNEXPECTED'])\n",
    "#         log_missing = len(df[df['key'] == 'LOG_MISSING'])\n",
    "        \n",
    "#         print(f\"\\nğŸ“Š ê²€ì¦ ê²°ê³¼ (click_type ì œì™¸):\")\n",
    "#         print(f\"   ì „ì²´: {total}ê°œ\")\n",
    "#         print(f\"   í†µê³¼: {passed}ê°œ ({passed/total*100:.1f}%)\" if total > 0 else \"   í†µê³¼: 0ê°œ\")\n",
    "#         print(f\"   ì‹¤íŒ¨: {failed}ê°œ\")\n",
    "#         print(f\"   ì˜ˆìƒì™¸: {unexpected}ê°œ\")\n",
    "#         print(f\"   ë¡œê·¸ëˆ„ë½: {log_missing}ê°œ\")\n",
    "\n",
    "# # ì‚¬ìš© ì˜ˆì‹œ\n",
    "# def run_simple_validator():\n",
    "#     validator = SimpleTSVValidator()\n",
    "    \n",
    "#     try:\n",
    "#         # TSV íŒŒì¼ ë¡œë“œ\n",
    "#         validator.load_tsv_file(\"tester.tsv\")  # ë˜ëŠ” ì‹¤ì œ íŒŒì¼ ê²½ë¡œ\n",
    "        \n",
    "#         # ê²€ì¦ ìˆ˜í–‰\n",
    "#         validator.validate_and_export(\"qa_result_click_type_excluded.xlsx\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     run_simple_validator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ì¦ ì™„ë£Œ: ì „ì²´ 245ê°œ, í†µê³¼ 107ê°œ (43.7%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "from typing import Dict, List\n",
    "\n",
    "class SimpleTSVValidator:\n",
    "    def __init__(self, exclude_keys=None):\n",
    "        self.test_cases = []\n",
    "        self.exclude_keys = exclude_keys if exclude_keys is not None else ['click_type']\n",
    "        \n",
    "    def load_tsv_file(self, file_path: str):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding='utf-8', header=1)\n",
    "            df.columns = df.columns.str.rstrip(',').str.strip()\n",
    "            \n",
    "            for col in df.columns:\n",
    "                if df[col].dtype == 'object':\n",
    "                    df[col] = df[col].astype(str).str.rstrip(',').str.strip()\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                def safe_str(value):\n",
    "                    if pd.isna(value) or str(value).lower() == 'nan':\n",
    "                        return ''\n",
    "                    return str(value).strip()\n",
    "                \n",
    "                expected_keys_str = safe_str(row['keys-ì •ë‹µ'])\n",
    "                expected_keys = [k.strip() for k in expected_keys_str.split(',') if k.strip() and k.strip().lower() != 'nan']\n",
    "                \n",
    "                actual_keys_str = safe_str(row['keys_combined'])\n",
    "                actual_keys = [k.strip() for k in actual_keys_str.split(',') if k.strip() and k.strip().lower() != 'nan']\n",
    "                \n",
    "                # ì œì™¸í•  í‚¤ë“¤ í•„í„°ë§\n",
    "                actual_keys_filtered = [k for k in actual_keys if k not in self.exclude_keys]\n",
    "                \n",
    "                values_str = safe_str(row['values_combined'])\n",
    "                values = self._parse_values_by_key_count(values_str, len(actual_keys))\n",
    "                \n",
    "                test_case = {\n",
    "                    'unique_id': idx + 1,\n",
    "                    'ê¸°ëŠ¥': safe_str(row['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str(row['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str(row['í™œë™']),\n",
    "                    'page_id': safe_str(row['page_id']),\n",
    "                    'act_type': safe_str(row['act_type']),\n",
    "                    'click_type': safe_str(row['click_type']),\n",
    "                    'expected_keys': expected_keys,\n",
    "                    'actual_keys': actual_keys_filtered,\n",
    "                    'actual_keys_original': actual_keys,\n",
    "                    'values': values\n",
    "                }\n",
    "                self.test_cases.append(test_case)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _parse_values_by_key_count(self, values_str: str, expected_count: int):\n",
    "        if not values_str or expected_count <= 0:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            csv_reader = csv.reader(io.StringIO(values_str), delimiter=',', quotechar='\"')\n",
    "            parsed_row = next(csv_reader, [])\n",
    "            cleaned_values = [v.strip() for v in parsed_row if v.strip() and v.strip().lower() != 'nan']\n",
    "            \n",
    "            if len(cleaned_values) == expected_count:\n",
    "                return cleaned_values\n",
    "            elif len(cleaned_values) > expected_count:\n",
    "                return self._merge_excess_values(cleaned_values, expected_count)\n",
    "            else:\n",
    "                while len(cleaned_values) < expected_count:\n",
    "                    cleaned_values.append('')\n",
    "                return cleaned_values\n",
    "        except:\n",
    "            simple_split = [v.strip() for v in values_str.split(',') if v.strip() and v.strip().lower() != 'nan']\n",
    "            if len(simple_split) == expected_count:\n",
    "                return simple_split\n",
    "            elif len(simple_split) > expected_count:\n",
    "                return self._merge_excess_values(simple_split, expected_count)\n",
    "            else:\n",
    "                while len(simple_split) < expected_count:\n",
    "                    simple_split.append('')\n",
    "                return simple_split\n",
    "    \n",
    "    def _merge_excess_values(self, split_values: list, expected_count: int):\n",
    "        if len(split_values) <= expected_count:\n",
    "            return split_values\n",
    "        \n",
    "        result = split_values[:2] if expected_count > 2 else split_values[:1]\n",
    "        \n",
    "        if expected_count > 2:\n",
    "            excess_count = len(split_values) - expected_count\n",
    "            middle_start = 2\n",
    "            middle_end = middle_start + excess_count + 1\n",
    "            \n",
    "            if middle_end < len(split_values):\n",
    "                middle_parts = split_values[middle_start:middle_end]\n",
    "                merged_middle = ', '.join(middle_parts)\n",
    "                result.append(merged_middle)\n",
    "                result.extend(split_values[middle_end:])\n",
    "            else:\n",
    "                remaining = split_values[middle_start:]\n",
    "                merged_remaining = ', '.join(remaining)\n",
    "                result.append(merged_remaining)\n",
    "        else:\n",
    "            remaining = split_values[len(result):]\n",
    "            merged_remaining = ', '.join(remaining)\n",
    "            result.append(merged_remaining)\n",
    "        \n",
    "        return result[:expected_count]\n",
    "    \n",
    "    def validate_and_export(self, output_file: str):\n",
    "        results = []\n",
    "        \n",
    "        def safe_str_result(value):\n",
    "            if pd.isna(value) or str(value).lower() == 'nan':\n",
    "                return ''\n",
    "            return str(value).strip()\n",
    "        \n",
    "        for test_case in self.test_cases:\n",
    "            unique_id = test_case['unique_id']\n",
    "            actual_keys = test_case['actual_keys']\n",
    "            expected_keys = test_case['expected_keys']\n",
    "            values = test_case['values']\n",
    "            actual_keys_original = test_case['actual_keys_original']\n",
    "            \n",
    "            if len(actual_keys) == 0 and len(expected_keys) > 0:\n",
    "                results.append({\n",
    "                    'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "                    'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "                    'page_id': safe_str_result(test_case['page_id']),\n",
    "                    'act_type': safe_str_result(test_case['act_type']),\n",
    "                    'click_type': safe_str_result(test_case['click_type']),\n",
    "                    'key': 'LOG_MISSING',\n",
    "                    'value': 'ë¡œê·¸ ëˆ„ë½',\n",
    "                    'pass': 'FAIL'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            if len(actual_keys) == 0 and len(expected_keys) == 0:\n",
    "                continue\n",
    "            \n",
    "            key_value_map = {}\n",
    "            for i, key in enumerate(actual_keys_original):\n",
    "                if i < len(values):\n",
    "                    key_value_map[key] = safe_str_result(values[i])\n",
    "                else:\n",
    "                    key_value_map[key] = ''\n",
    "            \n",
    "            actual_keys_set = set(actual_keys)\n",
    "            expected_keys_set = set(expected_keys)\n",
    "            \n",
    "            for key in expected_keys:\n",
    "                value = key_value_map.get(key, 'MISSING')\n",
    "                pass_status = 'PASS' if key in actual_keys_set else 'FAIL'\n",
    "                \n",
    "                results.append({\n",
    "                    'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "                    'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "                    'page_id': safe_str_result(test_case['page_id']),\n",
    "                    'act_type': safe_str_result(test_case['act_type']),\n",
    "                    'click_type': safe_str_result(test_case['click_type']),\n",
    "                    'key': key,\n",
    "                    'value': safe_str_result(value),\n",
    "                    'pass': pass_status\n",
    "                })\n",
    "            \n",
    "            unexpected_keys = actual_keys_set - expected_keys_set\n",
    "            for key in unexpected_keys:\n",
    "                value = key_value_map.get(key, '')\n",
    "                results.append({\n",
    "                    'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "                    'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "                    'page_id': safe_str_result(test_case['page_id']),\n",
    "                    'act_type': safe_str_result(test_case['act_type']),\n",
    "                    'click_type': safe_str_result(test_case['click_type']),\n",
    "                    'key': key,\n",
    "                    'value': safe_str_result(value),\n",
    "                    'pass': 'UNEXPECTED'\n",
    "                })\n",
    "        \n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results.to_excel(output_file, index=False, engine='openpyxl')\n",
    "        \n",
    "        total = len(df_results)\n",
    "        passed = len(df_results[df_results['pass'] == 'PASS'])\n",
    "        print(f\"ê²€ì¦ ì™„ë£Œ: ì „ì²´ {total}ê°œ, í†µê³¼ {passed}ê°œ ({passed/total*100:.1f}%)\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "def run_validator():\n",
    "    validator = SimpleTSVValidator(exclude_keys=['channel', 'page_url', 'os_name'])\n",
    "    validator.load_tsv_file(\"tester.tsv\")\n",
    "    validator.validate_and_export(\"./result/qa_result.xlsx\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_validator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²€ì¦ ì™„ë£Œ: ì „ì²´ 295ê°œ, í†µê³¼ 175ê°œ (59.3%)\n",
      "ì œì™¸ëœ í‚¤ë“¤: ['os_name']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import io\n",
    "import re\n",
    "from typing import Dict, List\n",
    "\n",
    "class SimpleTSVValidator:\n",
    "    def __init__(self, exclude_keys=None):\n",
    "        self.test_cases = []\n",
    "        self.exclude_keys = exclude_keys if exclude_keys is not None else ['click_type']\n",
    "        \n",
    "    def load_tsv_file(self, file_path: str):\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep='\\t', encoding='utf-8', header=0)\n",
    "            df.columns = df.columns.str.rstrip(',').str.strip()\n",
    "            \n",
    "            for col in df.columns:\n",
    "                if df[col].dtype == 'object':\n",
    "                    df[col] = df[col].astype(str).str.rstrip(',').str.strip()\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                def safe_str(value):\n",
    "                    if pd.isna(value) or str(value).lower() == 'nan':\n",
    "                        return ''\n",
    "                    return str(value).strip()\n",
    "                \n",
    "                expected_keys_str = safe_str(row['keys-ì •ë‹µ'])\n",
    "                expected_keys = [k.strip() for k in expected_keys_str.split(',') if k.strip() and k.strip().lower() != 'nan']\n",
    "                \n",
    "                actual_keys_str = safe_str(row['keys_combined'])\n",
    "                actual_keys = [k.strip() for k in actual_keys_str.split(',') if k.strip() and k.strip().lower() != 'nan']\n",
    "                \n",
    "                # ì œì™¸í•  í‚¤ë“¤ í•„í„°ë§\n",
    "                actual_keys_filtered = [k for k in actual_keys if k not in self.exclude_keys]\n",
    "                \n",
    "                values_str = safe_str(row['values_combined'])\n",
    "                values = self._parse_values_by_key_count(values_str, len(actual_keys))\n",
    "                \n",
    "                test_case = {\n",
    "                    'unique_id': idx + 1,\n",
    "                    'ê¸°ëŠ¥': safe_str(row['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str(row['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str(row['í™œë™']),\n",
    "                    'page_id': safe_str(row['page_id']),\n",
    "                    'act_type': safe_str(row['act_type']),\n",
    "                    'click_type': safe_str(row['click_type']),\n",
    "                    'expected_keys': expected_keys,\n",
    "                    'actual_keys': actual_keys_filtered,\n",
    "                    'actual_keys_original': actual_keys,\n",
    "                    'values': values\n",
    "                }\n",
    "                self.test_cases.append(test_case)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def _parse_values_by_key_count(self, values_str: str, expected_count: int):\n",
    "        if not values_str or expected_count <= 0:\n",
    "            return []\n",
    "        \n",
    "        # ëª¨ë“  ì½¤ë§ˆë¡œ ë¶„í• \n",
    "        all_parts = [v.strip() for v in values_str.split(',') if v.strip()]\n",
    "        \n",
    "        if len(all_parts) == expected_count:\n",
    "            return all_parts\n",
    "        elif len(all_parts) < expected_count:\n",
    "            while len(all_parts) < expected_count:\n",
    "                all_parts.append('')\n",
    "            return all_parts\n",
    "        else:\n",
    "            # ì´ˆê³¼ë¶„ì„ ì•ìª½ì— í•©ì¹˜ê¸° (ë’¤ìª½ ê°’ë“¤ì´ ë³´í†µ ë” ì•ˆì „í•¨)\n",
    "            excess = len(all_parts) - expected_count\n",
    "            merged_first = ', '.join(all_parts[:excess + 1])\n",
    "            result = [merged_first] + all_parts[excess + 1:]\n",
    "            return result\n",
    "    \n",
    "    def validate_and_export(self, output_file: str):\n",
    "        results = []\n",
    "        \n",
    "        def safe_str_result(value):\n",
    "            if pd.isna(value) or str(value).lower() == 'nan':\n",
    "                return ''\n",
    "            return str(value).strip()\n",
    "        \n",
    "        for test_case in self.test_cases:\n",
    "            unique_id = test_case['unique_id']\n",
    "            actual_keys = test_case['actual_keys']  # ì´ë¯¸ í•„í„°ë§ëœ í‚¤ë“¤\n",
    "            expected_keys = test_case['expected_keys']\n",
    "            values = test_case['values']\n",
    "            actual_keys_original = test_case['actual_keys_original']\n",
    "            \n",
    "            # expected_keysì—ì„œë„ ì œì™¸í•  í‚¤ë“¤ í•„í„°ë§ âœ… ìˆ˜ì •ë¨\n",
    "            expected_keys_filtered = [k for k in expected_keys if k not in self.exclude_keys]\n",
    "            \n",
    "            if len(actual_keys) == 0 and len(expected_keys_filtered) > 0:\n",
    "                results.append({\n",
    "                    'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "                    'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "                    'page_id': safe_str_result(test_case['page_id']),\n",
    "                    'act_type': safe_str_result(test_case['act_type']),\n",
    "                    'click_type': safe_str_result(test_case['click_type']),\n",
    "                    'key': 'LOG_MISSING',\n",
    "                    'value': 'ë¡œê·¸ ëˆ„ë½',\n",
    "                    'pass': 'FAIL'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            if len(actual_keys) == 0 and len(expected_keys_filtered) == 0:\n",
    "                continue\n",
    "            \n",
    "            # key-value ë§¤í•‘: ì›ë³¸ í‚¤ë“¤ê³¼ ê°’ë“¤ì„ 1:1 ë§¤í•‘\n",
    "            key_value_map = {}\n",
    "            for i, key in enumerate(actual_keys_original):\n",
    "                if i < len(values):\n",
    "                    key_value_map[key] = safe_str_result(values[i])\n",
    "                else:\n",
    "                    key_value_map[key] = ''\n",
    "            \n",
    "            # í•„í„°ë§ëœ í‚¤ë“¤ë¡œ ì§‘í•© ìƒì„± âœ… ìˆ˜ì •ë¨\n",
    "            actual_keys_set = set(actual_keys)  # ì´ë¯¸ ì œì™¸ í‚¤ í•„í„°ë§ëœ í‚¤ë“¤\n",
    "            expected_keys_set = set(expected_keys_filtered)  # ì œì™¸ í‚¤ í•„í„°ë§ëœ ì˜ˆìƒ í‚¤ë“¤\n",
    "            \n",
    "            # expected_keys_filtered ê²€ì¦ âœ… ìˆ˜ì •ë¨\n",
    "            for key in expected_keys_filtered:\n",
    "                # key_value_mapì—ì„œ ê°’ ì¶”ì¶œ (ì›ë³¸ í‚¤ë“¤ë¡œ ë§¤í•‘ëœ ê²ƒì—ì„œ)\n",
    "                value = key_value_map.get(key, 'MISSING')\n",
    "                # actual_keys_setì— ìˆëŠ”ì§€ í™•ì¸ (ì œì™¸ í‚¤ í•„í„°ë§ëœ ê²ƒì—ì„œ)\n",
    "                pass_status = 'PASS' if key in actual_keys_set or key in ['channel', 'page_url'] else 'FAIL'\n",
    "                \n",
    "                results.append({\n",
    "                    'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "                    'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "                    'page_id': safe_str_result(test_case['page_id']),\n",
    "                    'act_type': safe_str_result(test_case['act_type']),\n",
    "                    'click_type': safe_str_result(test_case['click_type']),\n",
    "                    'key': key,\n",
    "                    'value': safe_str_result(value),\n",
    "                    'pass': pass_status\n",
    "                })\n",
    "            \n",
    "            unexpected_keys = actual_keys_set - expected_keys_set\n",
    "            for key in unexpected_keys:\n",
    "                value = key_value_map.get(key, '')\n",
    "                if key in ['channel', 'page_url']:\n",
    "                    pass_status = 'PASS'\n",
    "                else:\n",
    "                    pass_status = 'UNEXPECTED'\n",
    "                results.append({\n",
    "                    'ê³ ìœ ë²ˆí˜¸': unique_id,\n",
    "                    'ê¸°ëŠ¥': safe_str_result(test_case['ê¸°ëŠ¥']),\n",
    "                    'ê²½ë¡œ': safe_str_result(test_case['ê²½ë¡œ']),\n",
    "                    'í™œë™': safe_str_result(test_case['í™œë™']),\n",
    "                    'page_id': safe_str_result(test_case['page_id']),\n",
    "                    'act_type': safe_str_result(test_case['act_type']),\n",
    "                    'click_type': safe_str_result(test_case['click_type']),\n",
    "                    'key': key,\n",
    "                    'value': safe_str_result(value),\n",
    "                    'pass': pass_status\n",
    "                })\n",
    "        \n",
    "        df_results = pd.DataFrame(results)\n",
    "        df_results.to_excel(output_file, index=False, engine='openpyxl')\n",
    "        \n",
    "        total = len(df_results)\n",
    "        passed = len(df_results[df_results['pass'] == 'PASS'])\n",
    "        print(f\"ê²€ì¦ ì™„ë£Œ: ì „ì²´ {total}ê°œ, í†µê³¼ {passed}ê°œ ({passed/total*100:.1f}%)\")\n",
    "        print(f\"ì œì™¸ëœ í‚¤ë“¤: {self.exclude_keys}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "def run_validator():\n",
    "    # channel, page_url, os_name ì œê±°\n",
    "    validator = SimpleTSVValidator(exclude_keys=['os_name'])\n",
    "    validator.load_tsv_file(\"tester.tsv\")\n",
    "    validator.validate_and_export(\"./result/qa_result.xlsx\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_validator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
