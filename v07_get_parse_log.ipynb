{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== JSON 로그를 Excel 형태로 변환 ===\n",
      "📌 생성 파일:\n",
      "   - log_analysis_detailed.xlsx (상세 형태)\n",
      "   - log_analysis_combined_no_comma_filled.xlsx (결합 형태, 쉼표 제거)\n",
      "\n",
      "✅ 모든 JSON 파싱 성공\n",
      "✅ 로그 파일 로드 완료: 3개 로그\n",
      "✅ 상세 데이터 변환 완료: 16개 key-value 쌍\n",
      "✅ 쉼표 제거된 결합 데이터 변환 완료: 3개 로그\n",
      "✅ 상세 데이터에서 누락된 번호가 없습니다.\n",
      "✅ 쉼표 제거된 결합 데이터에서 누락된 번호가 없습니다.\n",
      "✅ 상세 Excel 파일 저장: ./result/log_analysis_detailed.xlsx\n",
      "✅ 결합 Excel 파일 저장: ./result/log_analysis_combined_no_comma_filled.xlsx\n",
      "✅ 변환 완료:\n",
      "   - 상세 형태: ./result/log_analysis_detailed.xlsx\n",
      "   - 결합 형태 (쉼표 제거): ./result/log_analysis_combined_no_comma_filled.xlsx\n",
      "   - 처리된 로그: 3개\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict\n",
    "import re\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "from datetime import datetime\n",
    "\n",
    "class LogToDetailedConverter:\n",
    "    \"\"\"JSON 로그를 Excel 형태로 변환하는 간소화된 클래스\"\"\"\n",
    "    def __init__(self):\n",
    "        self.input_data = []\n",
    "        self.detailed_data = []\n",
    "        self.combined_data_no_comma = []\n",
    "\n",
    "    def convert_log_files(self, input_log_path: str):\n",
    "        \"\"\"\n",
    "        JSON 로그 파일을 2개의 Excel 파일로 변환\n",
    "        - log_analysis_detailed.xlsx\n",
    "        - log_analysis_combined_no_comma_filled.xlsx\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # 1. 입력 로그 파일 읽기\n",
    "            self._load_log_file(input_log_path)\n",
    "            \n",
    "            # 2. 상세 데이터로 변환\n",
    "            self._convert_to_detailed()\n",
    "            \n",
    "            # 3. 쉼표 제거된 결합 데이터로 변환\n",
    "            self._convert_to_combined_no_comma()\n",
    "            \n",
    "            # 4. 누락된 행 채우기\n",
    "            self._fill_missing_rows_in_detailed_data()\n",
    "            self._fill_missing_rows_in_combined_no_comma()\n",
    "            \n",
    "            # 5. 파일 저장\n",
    "            self._save_detailed_excel(\"./result/log_analysis_detailed.xlsx\")\n",
    "            self._save_combined_no_comma_excel(\"./result/log_analysis_combined_no_comma_filled.xlsx\")\n",
    "            \n",
    "            print(f\"✅ 변환 완료:\")\n",
    "            print(f\"   - 상세 형태: ./result/log_analysis_detailed.xlsx\")\n",
    "            print(f\"   - 결합 형태 (쉼표 제거): ./result/log_analysis_combined_no_comma_filled.xlsx\")\n",
    "            print(f\"   - 처리된 로그: {len(self.input_data)}개\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 변환 중 오류 발생: {e}\")\n",
    "\n",
    "    def _load_log_file(self, log_path: str):\n",
    "        \"\"\"JSON 로그 파일 로드 및 파싱 (오류 자동 수정 기능 포함)\"\"\"\n",
    "        try:\n",
    "            self.input_data = []\n",
    "            json_errors = []\n",
    "            fixed_count = 0\n",
    "            \n",
    "            with open(log_path, 'r', encoding='utf-8') as file:\n",
    "                for line_no, line in enumerate(file, 1):\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # JSON 파싱\n",
    "                        log_entry = json.loads(line)\n",
    "                        parsed_data = self._process_new_log_format(log_entry)\n",
    "                        \n",
    "                        if parsed_data:\n",
    "                            parsed_data['log_line'] = line_no\n",
    "                            self.input_data.append(parsed_data)\n",
    "                    \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        json_errors.append((line_no, str(e), line))\n",
    "                        \n",
    "                        # JSON 수정 시도\n",
    "                        fixed_line = self._try_fix_json(line)\n",
    "                        if fixed_line:\n",
    "                            try:\n",
    "                                log_entry = json.loads(fixed_line)\n",
    "                                parsed_data = self._process_new_log_format(log_entry)\n",
    "                                \n",
    "                                if parsed_data:\n",
    "                                    parsed_data['log_line'] = line_no\n",
    "                                    self.input_data.append(parsed_data)\n",
    "                                    fixed_count += 1\n",
    "                                    print(f\"✅ JSON 수정 성공 (라인 {line_no})\")\n",
    "                            except:\n",
    "                                # 추가 수정 시도\n",
    "                                fixed_line2 = self._force_fix_json(line)\n",
    "                                if fixed_line2:\n",
    "                                    try:\n",
    "                                        log_entry = json.loads(fixed_line2)\n",
    "                                        parsed_data = self._process_new_log_format(log_entry)\n",
    "                                        \n",
    "                                        if parsed_data:\n",
    "                                            parsed_data['log_line'] = line_no\n",
    "                                            self.input_data.append(parsed_data)\n",
    "                                            fixed_count += 1\n",
    "                                            print(f\"✅ 강제 JSON 수정 성공 (라인 {line_no})\")\n",
    "                                    except:\n",
    "                                        print(f\"❌ JSON 수정 실패 (라인 {line_no}): {e}\")\n",
    "                                else:\n",
    "                                    print(f\"❌ JSON 수정 실패 (라인 {line_no}): {e}\")\n",
    "                        else:\n",
    "                            print(f\"❌ JSON 수정 실패 (라인 {line_no}): {e}\")\n",
    "            \n",
    "            # 오류 요약 출력\n",
    "            if json_errors:\n",
    "                print(f\"⚠️ JSON 파싱 오류 발생: {len(json_errors)}개\")\n",
    "                if fixed_count > 0:\n",
    "                    print(f\"✅ 수정 성공: {fixed_count}개\")\n",
    "                print(f\"✅ 최종 파싱된 로그: {len(self.input_data)}개\")\n",
    "            else:\n",
    "                print(f\"✅ 모든 JSON 파싱 성공\")\n",
    "            \n",
    "            print(f\"✅ 로그 파일 로드 완료: {len(self.input_data)}개 로그\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"❌ 파일을 찾을 수 없습니다: {log_path}\")\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 파일 로드 오류: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _process_new_log_format(self, log_entry: dict) -> dict:\n",
    "        \"\"\"새로운 로그 형식 처리: 직접 key-value 객체, 빈 값 제외, 특정 필드 제외\"\"\"\n",
    "        # 제외할 필드들\n",
    "        exclude_fields = {'client_ip', 'os_version', 'platform_type', 'device_model', 'device_maker', 'event_dt', 'nth_pcid', 'nth_sid', 'user_seq'}\n",
    "        \n",
    "        # 처리된 데이터\n",
    "        processed_data = {}\n",
    "        \n",
    "        # event_dttm을 logtime으로 변환\n",
    "        if 'event_dttm' in log_entry:\n",
    "            processed_data['logtime'] = log_entry['event_dttm']\n",
    "        \n",
    "        # 각 key-value 쌍 처리\n",
    "        for key, value in log_entry.items():\n",
    "            # 제외 필드는 건너뛰기\n",
    "            if key in exclude_fields:\n",
    "                continue\n",
    "            \n",
    "            # event_dttm은 이미 logtime으로 처리했으므로 건너뛰기\n",
    "            if key == 'event_dttm':\n",
    "                continue\n",
    "            \n",
    "            # 빈 문자열(\"\")인 값은 제외\n",
    "            if value == \"\":\n",
    "                continue\n",
    "            \n",
    "            # 유효한 key-value 쌍만 포함\n",
    "            processed_data[key] = value\n",
    "        \n",
    "        return processed_data\n",
    "\n",
    "    def _try_fix_json(self, line: str) -> str:\n",
    "        \"\"\"JSON 수정 시도 - 1차 수정\"\"\"\n",
    "        try:\n",
    "            # 1. 마지막 쉼표 제거\n",
    "            if line.endswith(',}'):\n",
    "                line = line[:-2] + '}'\n",
    "            elif line.endswith(',]'):\n",
    "                line = line[:-2] + ']'\n",
    "            \n",
    "            # 2. 값 내부의 따옴표를 작은따옴표로 변경\n",
    "            import re\n",
    "            \n",
    "            # 모든 \"key\":\"value with quotes\" 패턴을 찾아서 수정\n",
    "            def fix_quotes_in_value(match):\n",
    "                key = match.group(1)\n",
    "                value = match.group(2)\n",
    "                # 값 내부의 모든 따옴표를 작은따옴표로 변경\n",
    "                fixed_value = value.replace('\"', \"'\")\n",
    "                return f'\"{key}\":\"{fixed_value}\"'\n",
    "            \n",
    "            # 값에 따옴표가 포함된 패턴 찾기\n",
    "            problem_pattern = r'\"([^\"]+)\":\"([^\"]*\"[^\"]*)\"'\n",
    "            \n",
    "            # 여러 번 적용하여 모든 문제 해결\n",
    "            prev_line = \"\"\n",
    "            iterations = 0\n",
    "            while line != prev_line and iterations < 5:\n",
    "                prev_line = line\n",
    "                line = re.sub(problem_pattern, fix_quotes_in_value, line)\n",
    "                iterations += 1\n",
    "            \n",
    "            return line\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _force_fix_json(self, line: str) -> str:\n",
    "        \"\"\"JSON 강제 수정 - 2차 수정\"\"\"\n",
    "        try:\n",
    "            # 기본 정리\n",
    "            if line.endswith(',}'):\n",
    "                line = line[:-2] + '}'\n",
    "            elif line.endswith(',]'):\n",
    "                line = line[:-2] + ']'\n",
    "            \n",
    "            # JSON 구조 분석하여 키-값 쌍별로 처리\n",
    "            if not (line.startswith('{') and line.endswith('}')):\n",
    "                return None\n",
    "            \n",
    "            # 중괄호 제거\n",
    "            content = line[1:-1]\n",
    "            \n",
    "            # 키-값 쌍들을 분리\n",
    "            pairs = []\n",
    "            current_pair = \"\"\n",
    "            bracket_count = 0\n",
    "            in_quotes = False\n",
    "            escape_next = False\n",
    "            \n",
    "            for char in content:\n",
    "                if escape_next:\n",
    "                    current_pair += char\n",
    "                    escape_next = False\n",
    "                    continue\n",
    "                \n",
    "                if char == '\\\\':\n",
    "                    current_pair += char\n",
    "                    escape_next = True\n",
    "                    continue\n",
    "                \n",
    "                if char == '\"' and not escape_next:\n",
    "                    in_quotes = not in_quotes\n",
    "                \n",
    "                if not in_quotes:\n",
    "                    if char in '{}[]':\n",
    "                        bracket_count += 1 if char in '{[' else -1\n",
    "                    elif char == ',' and bracket_count == 0:\n",
    "                        pairs.append(current_pair.strip())\n",
    "                        current_pair = \"\"\n",
    "                        continue\n",
    "                \n",
    "                current_pair += char\n",
    "            \n",
    "            if current_pair.strip():\n",
    "                pairs.append(current_pair.strip())\n",
    "            \n",
    "            # 각 키-값 쌍을 수정\n",
    "            fixed_pairs = []\n",
    "            for pair in pairs:\n",
    "                if ':' in pair:\n",
    "                    try:\n",
    "                        # 키와 값 분리 (첫 번째 콜론 기준)\n",
    "                        colon_pos = pair.find(':')\n",
    "                        key_part = pair[:colon_pos].strip()\n",
    "                        value_part = pair[colon_pos+1:].strip()\n",
    "                        \n",
    "                        # 값 부분에서 따옴표로 둘러싸인 문자열인지 확인\n",
    "                        if value_part.startswith('\"') and value_part.endswith('\"'):\n",
    "                            # 값 내부의 따옴표를 작은따옴표로 변경\n",
    "                            inner_value = value_part[1:-1]  # 양쪽 따옴표 제거\n",
    "                            fixed_inner = inner_value.replace('\"', \"'\")\n",
    "                            fixed_value = f'\"{fixed_inner}\"'\n",
    "                            fixed_pairs.append(f'{key_part}:{fixed_value}')\n",
    "                        else:\n",
    "                            fixed_pairs.append(pair)\n",
    "                    except:\n",
    "                        fixed_pairs.append(pair)\n",
    "                else:\n",
    "                    fixed_pairs.append(pair)\n",
    "            \n",
    "            # 다시 조합\n",
    "            result = '{' + ','.join(fixed_pairs) + '}'\n",
    "            return result\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _fix_korean_text(self, text: str) -> str:\n",
    "        \"\"\"깨진 한글을 올바르게 디코딩\"\"\"\n",
    "        try:\n",
    "            # URL 디코딩 먼저 시도\n",
    "            from urllib.parse import unquote\n",
    "            decoded = unquote(text, encoding='utf-8')\n",
    "            \n",
    "            # 깨진 한글 패턴이 있는지 확인\n",
    "            if self._has_broken_korean(decoded):\n",
    "                # Latin-1로 인코딩 후 UTF-8로 디코딩\n",
    "                try:\n",
    "                    fixed = decoded.encode('latin-1').decode('utf-8')\n",
    "                    return fixed\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                # 그래도 안되면 바이트 단위로 처리\n",
    "                try:\n",
    "                    byte_data = bytes([ord(c) for c in decoded if ord(c) < 256])\n",
    "                    fixed = byte_data.decode('utf-8', errors='ignore')\n",
    "                    return fixed\n",
    "                except:\n",
    "                    pass\n",
    "                    \n",
    "                # UTF-8 바이트 패턴으로 복구 시도\n",
    "                try:\n",
    "                    # 특정 깨진 패턴들을 직접 매핑\n",
    "                    broken_patterns = {\n",
    "                        'ê·¹ììëª¨': '극장용모',\n",
    "                        'í¥ê¸°ë¡­ê²': '향기롭게',\n",
    "                        'ì¤ê¸°ì¼ì´': '수기일이',\n",
    "                        'ììëª¨': '용모',\n",
    "                        'ê·¹': '극'\n",
    "                    }\n",
    "                    \n",
    "                    result = decoded\n",
    "                    for broken, fixed in broken_patterns.items():\n",
    "                        result = result.replace(broken, fixed)\n",
    "                    \n",
    "                    if result != decoded:\n",
    "                        return result\n",
    "                        \n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            return decoded\n",
    "            \n",
    "        except Exception:\n",
    "            return text\n",
    "\n",
    "    def _has_broken_korean(self, text: str) -> bool:\n",
    "        \"\"\"깨진 한글 패턴이 있는지 확인\"\"\"\n",
    "        broken_patterns = [\n",
    "            'ë¶', 'ìë', 'ê¼¬', 'ë', 'í¼', 'ì¸', 'ê¸°', 'ê¸', 'ìì¹', 'ì', 'ê',\n",
    "            'ê·¹ì', 'í¥ê¸°', 'ì¤ê¸°', 'ììë', 'ëª¨'\n",
    "        ]\n",
    "        return any(pattern in text for pattern in broken_patterns)\n",
    "\n",
    "    def _format_logtime(self, logtime_str: str) -> str:\n",
    "        \"\"\"LOGTIME을 yyyy-mm-dd HH:MM:SS 형식으로 변환\"\"\"\n",
    "        try:\n",
    "            if not logtime_str:\n",
    "                return ''\n",
    "            \n",
    "            # 새로운 형식: \"2025-06-05T15:04:00.041\" (ISO 8601)\n",
    "            if 'T' in logtime_str:\n",
    "                try:\n",
    "                    # ISO 8601 형식 파싱\n",
    "                    if '.' in logtime_str:\n",
    "                        dt = datetime.fromisoformat(logtime_str.replace('Z', '+00:00'))\n",
    "                    else:\n",
    "                        dt = datetime.fromisoformat(logtime_str.replace('Z', '+00:00'))\n",
    "                    \n",
    "                    # yyyy-mm-dd HH:MM:SS 형식으로 변환\n",
    "                    formatted_time = dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                    return formatted_time\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # 기존 형식: \"04/Jun/2025:21:46:25 +0900\"\n",
    "            month_map = {\n",
    "                'Jan': '01', 'Feb': '02', 'Mar': '03', 'Apr': '04',\n",
    "                'May': '05', 'Jun': '06', 'Jul': '07', 'Aug': '08',\n",
    "                'Sep': '09', 'Oct': '10', 'Nov': '11', 'Dec': '12'\n",
    "            }\n",
    "            \n",
    "            # 정규식으로 파싱\n",
    "            pattern = r'(\\d{2})/(\\w{3})/(\\d{4}):(\\d{2}):(\\d{2}):(\\d{2})\\s*\\+\\d{4}'\n",
    "            match = re.match(pattern, logtime_str)\n",
    "            \n",
    "            if match:\n",
    "                day, month_name, year, hour, minute, second = match.groups()\n",
    "                month = month_map.get(month_name, '01')\n",
    "                formatted_time = f\"{year}-{month}-{day} {hour}:{minute}:{second}\"\n",
    "                return formatted_time\n",
    "            else:\n",
    "                return logtime_str\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ LOGTIME 변환 오류: {e} - 원본: {logtime_str}\")\n",
    "            return logtime_str\n",
    "\n",
    "    def _convert_to_detailed(self):\n",
    "        \"\"\"로그 데이터를 상세 key-value 행으로 변환\"\"\"\n",
    "        self.detailed_data = []\n",
    "        \n",
    "        # 제외할 기본 필드들 (메타데이터)\n",
    "        exclude_fields = {'log_line', 'logtime'}\n",
    "        \n",
    "        for log_entry in self.input_data:\n",
    "            log_no = log_entry.get('log_line', 0)\n",
    "            \n",
    "            # 기본 정보 추출\n",
    "            page_id = log_entry.get('page_id', '')\n",
    "            click_type = log_entry.get('click_type', '')\n",
    "            act_type = log_entry.get('act_type', '')\n",
    "            click_text = log_entry.get('click_text', '')\n",
    "            \n",
    "            # LOGTIME 포맷 변환\n",
    "            raw_logtime = log_entry.get('logtime', '')\n",
    "            formatted_logtime = self._format_logtime(raw_logtime)\n",
    "            \n",
    "            # 나머지 파라미터들을 key-value 쌍으로 처리\n",
    "            for key, value in log_entry.items():\n",
    "                if key in exclude_fields:\n",
    "                    continue\n",
    "                \n",
    "                self.detailed_data.append({\n",
    "                    'no': log_no,\n",
    "                    'log_time': formatted_logtime,\n",
    "                    'page_id': page_id,\n",
    "                    'click_type': click_type,\n",
    "                    'act_type': act_type,\n",
    "                    'click_text': click_text,\n",
    "                    'key': key,\n",
    "                    'value': str(value) if value is not None else ''\n",
    "                })\n",
    "        \n",
    "        print(f\"✅ 상세 데이터 변환 완료: {len(self.detailed_data)}개 key-value 쌍\")\n",
    "\n",
    "    def _convert_to_combined_no_comma(self):\n",
    "        \"\"\"로그 데이터를 쉼표 제거된 결합 형태로 변환\"\"\"\n",
    "        self.combined_data_no_comma = []\n",
    "        \n",
    "        # 제외할 기본 필드들\n",
    "        exclude_fields = {'log_line', 'logtime', 'clientip', 'useragent', 'status'}\n",
    "        \n",
    "        for log_entry in self.input_data:\n",
    "            log_no = log_entry.get('log_line', 0)\n",
    "            \n",
    "            # 기본 정보 추출\n",
    "            page_id = log_entry.get('page_id', '')\n",
    "            click_type = log_entry.get('click_type', '')\n",
    "            act_type = log_entry.get('act_type', '')\n",
    "            click_text = log_entry.get('click_text', '')\n",
    "            \n",
    "            # 나머지 파라미터들 수집\n",
    "            keys = []\n",
    "            values = []\n",
    "            \n",
    "            for key, value in log_entry.items():\n",
    "                if key not in exclude_fields:\n",
    "                    keys.append(key)\n",
    "                    # 각 개별 value 내부의 쉼표만 제거\n",
    "                    clean_value = str(value).replace(',', '') if value is not None else ''\n",
    "                    values.append(clean_value)\n",
    "            \n",
    "            # 키와 값을 쉼표로 구분된 문자열로 결합\n",
    "            keys_combined = ', '.join(keys) if keys else ''\n",
    "            values_combined = ', '.join(values) if values else ''\n",
    "            \n",
    "            combined_entry = {\n",
    "                'no': log_no,\n",
    "                'page_id': page_id,\n",
    "                'click_type': click_type,\n",
    "                'act_type': act_type,\n",
    "                'keys_combined': keys_combined,\n",
    "                'values_combined': values_combined,\n",
    "                'key_count': len(keys)\n",
    "            }\n",
    "            \n",
    "            # click_text가 있으면 추가 (내부 쉼표 제거)\n",
    "            if click_text:\n",
    "                combined_entry['click_text'] = str(click_text).replace(',', '')\n",
    "            \n",
    "            self.combined_data_no_comma.append(combined_entry)\n",
    "        \n",
    "        print(f\"✅ 쉼표 제거된 결합 데이터 변환 완료: {len(self.combined_data_no_comma)}개 로그\")\n",
    "\n",
    "    def _fill_missing_rows_in_detailed_data(self):\n",
    "        \"\"\"detailed_data에서 누락된 no 번호에 빈 행을 추가\"\"\"\n",
    "        if not self.detailed_data:\n",
    "            print(\"⚠️ 상세 데이터가 없어 누락된 행을 채울 수 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        # 현재 no 값들 추출 (중복 제거)\n",
    "        current_nos = list(set([item['no'] for item in self.detailed_data]))\n",
    "        min_no = min(current_nos)\n",
    "        max_no = max(current_nos)\n",
    "        \n",
    "        # 전체 범위의 no 리스트 생성\n",
    "        full_range = set(range(min_no, max_no + 1))\n",
    "        existing_nos = set(current_nos)\n",
    "        missing_nos = sorted(full_range - existing_nos)\n",
    "        \n",
    "        if not missing_nos:\n",
    "            print(\"✅ 상세 데이터에서 누락된 번호가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"📌 상세 데이터에서 누락된 번호: {missing_nos}\")\n",
    "        \n",
    "        # 기본 빈 행 템플릿 생성\n",
    "        template_row = self.detailed_data[0].copy()\n",
    "        \n",
    "        # 누락된 번호들에 대한 빈 행 생성\n",
    "        for missing_no in missing_nos:\n",
    "            empty_row = template_row.copy()\n",
    "            empty_row['no'] = missing_no\n",
    "            empty_row['log_time'] = ''\n",
    "            empty_row['page_id'] = ''\n",
    "            empty_row['click_type'] = ''\n",
    "            empty_row['act_type'] = ''\n",
    "            empty_row['click_text'] = ''\n",
    "            empty_row['key'] = 'NO_LOG'\n",
    "            empty_row['value'] = 'Missing Log Entry'\n",
    "            \n",
    "            self.detailed_data.append(empty_row)\n",
    "        \n",
    "        # no 순으로 정렬\n",
    "        self.detailed_data.sort(key=lambda x: x['no'])\n",
    "        \n",
    "        print(f\"✅ 상세 데이터에서 누락된 {len(missing_nos)}개 행을 추가했습니다.\")\n",
    "\n",
    "    def _fill_missing_rows_in_combined_no_comma(self):\n",
    "        \"\"\"combined_data_no_comma에서 누락된 no 번호에 빈 행을 추가\"\"\"\n",
    "        if not self.combined_data_no_comma:\n",
    "            print(\"⚠️ 쉼표 제거된 결합 데이터가 없어 누락된 행을 채울 수 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        # 현재 no 값들 추출\n",
    "        current_nos = [item['no'] for item in self.combined_data_no_comma]\n",
    "        min_no = min(current_nos)\n",
    "        max_no = max(current_nos)\n",
    "        \n",
    "        # 전체 범위의 no 리스트 생성\n",
    "        full_range = set(range(min_no, max_no + 1))\n",
    "        existing_nos = set(current_nos)\n",
    "        missing_nos = sorted(full_range - existing_nos)\n",
    "        \n",
    "        if not missing_nos:\n",
    "            print(\"✅ 쉼표 제거된 결합 데이터에서 누락된 번호가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"📌 쉼표 제거된 결합 데이터에서 누락된 번호: {missing_nos}\")\n",
    "        \n",
    "        # 기본 빈 행 템플릿 생성\n",
    "        template_row = self.combined_data_no_comma[0].copy()\n",
    "        \n",
    "        # 누락된 번호들에 대한 빈 행 생성\n",
    "        for missing_no in missing_nos:\n",
    "            empty_row = template_row.copy()\n",
    "            empty_row['no'] = missing_no\n",
    "            empty_row['page_id'] = ''\n",
    "            empty_row['click_type'] = ''\n",
    "            empty_row['act_type'] = ''\n",
    "            empty_row['keys_combined'] = ''\n",
    "            empty_row['values_combined'] = ''\n",
    "            empty_row['key_count'] = 0\n",
    "            \n",
    "            # click_text가 있으면 빈 값으로 설정\n",
    "            if 'click_text' in empty_row:\n",
    "                empty_row['click_text'] = ''\n",
    "            \n",
    "            self.combined_data_no_comma.append(empty_row)\n",
    "        \n",
    "        # no 순으로 정렬\n",
    "        self.combined_data_no_comma.sort(key=lambda x: x['no'])\n",
    "        \n",
    "        print(f\"✅ 쉼표 제거된 결합 데이터에서 누락된 {len(missing_nos)}개 행을 추가했습니다.\")\n",
    "\n",
    "    def _save_detailed_excel(self, output_path: str):\n",
    "        \"\"\"상세 데이터를 Excel 파일로 저장\"\"\"\n",
    "        try:\n",
    "            df = pd.DataFrame(self.detailed_data)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"⚠️ 저장할 상세 데이터가 없습니다.\")\n",
    "                return\n",
    "            \n",
    "            # 컬럼 순서 정의\n",
    "            column_order = ['no', 'log_time', 'page_id', 'act_type', 'click_type', 'click_text', 'key', 'value']\n",
    "            \n",
    "            # 존재하는 컬럼만 선택\n",
    "            available_columns = [col for col in column_order if col in df.columns]\n",
    "            df = df[available_columns]\n",
    "            \n",
    "            # Excel 파일 저장\n",
    "            df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            \n",
    "            print(f\"✅ 상세 Excel 파일 저장: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 파일 저장 오류: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _save_combined_no_comma_excel(self, output_path: str):\n",
    "        \"\"\"value 내부 쉼표 제거된 결합 데이터를 Excel 파일로 저장\"\"\"\n",
    "        try:\n",
    "            df = pd.DataFrame(self.combined_data_no_comma)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"⚠️ 저장할 결합 데이터가 없습니다.\")\n",
    "                return\n",
    "            \n",
    "            # 컬럼 순서 정의\n",
    "            column_order = ['no', 'page_id', 'click_type', 'act_type', 'keys_combined', 'values_combined', 'key_count']\n",
    "            \n",
    "            # click_text 컬럼이 있으면 추가\n",
    "            if 'click_text' in df.columns:\n",
    "                column_order.insert(4, 'click_text')\n",
    "            \n",
    "            # 존재하는 컬럼만 선택\n",
    "            available_columns = [col for col in column_order if col in df.columns]\n",
    "            df = df[available_columns]\n",
    "            \n",
    "            # Excel 파일 저장\n",
    "            df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "            \n",
    "            print(f\"✅ 결합 Excel 파일 저장: {output_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ 파일 저장 오류: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    converter = LogToDetailedConverter()\n",
    "    \n",
    "    print(\"=== JSON 로그를 Excel 형태로 변환 ===\")\n",
    "    print(\"📌 생성 파일:\")\n",
    "    print(\"   - log_analysis_detailed.xlsx (상세 형태)\")\n",
    "    print(\"   - log_analysis_combined_no_comma_filled.xlsx (결합 형태, 쉼표 제거)\\n\")\n",
    "    \n",
    "    # 로그 파일 변환\n",
    "    converter.convert_log_files(\"./log/log_file.txt\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
